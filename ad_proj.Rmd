---
title: 'PROJECTE ANÀLISI DE DADES: Wine Quality'
author: "David Anglada Rotger i Andreu Huguet Segarra"
date: "15/6/2019"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    toc: yes
fig_width: 5
fig_height: 3
---

# Introducció

Avui en dia, el rang de consumidors del vi s'ha amplitat moltíssims, convertint-se amb una beguda que es pot trobar a totes les cases i, fins i tot, comparable amb la cervesa. Això ha provocat que l'interés per aquest producte hagi augmentat els darrers anys, provocant també un creixement de la indústria de la vineria. Com a conseqüència, el nombre d'investigacions i estudis que tenen com a finalitat la millora de la qualitat del vi o la pujada de les seves vendes s'ha disparat.

Un dels temes que preocupa més a aquest sector és la **certificació de qualitat**, un aspecte que depèn profundament de la catació i valoració d'enòlegs experts. Així doncs, la finalitat d'aquest estudi és estudiar quines variables afecten més a la qualitat final del vi i de quina manera influeixen.

Donat que algunes d'aquestes variables es poden controlar durant el procés de producció, serà interessant veure les que influeixen possitivament amb l'objectiu de potenciar-les, o detectar les que influeixen negativament per poder intentar neutralitzar el seu efecte.

# Descripció de la Base de Dades

Per la realització d'aquest estudi es disposa d'una base de dades amb 1599 entrades diferents. Cada una es correspon amb la certificació de qualitat d'un vi en particular (en particular, la base de dades la formen mostres de *vinho verde*, un dels vins més importants de tot Portugal), acompanyat de 11 variables fisicoquímiques més. Aquestes variables són el resultat de tests objectius, menys la variable resposta, la qualitat, que és la mitjana de la valoració de 3 enòlegs experts. Cada expert va otorgar una puntuació entre el 0 (dolent) al 10 (excel.lent).

Les 12 variables del *dataset* són les següents:

- **fixed.acidity**: Acidesa fixada.
- **volatile.acidity**: Acidesa volàtil.
- **citric.acid**: Àcid cítric.
- **residual.sugar**: Sucre residual.
- **chlorides**: Clorurs.
- **free.sulfur.dioxide**: Diòxid de sofre lliure.
- **total.sulfur.dioxide**: Totat de diòxid de sofre.
- **density**: Densitat.
- **pH**: pH.
- **sulphates**: Sulfats.
- **alcohol**: Alcohol.
- **quality**: Qualitat. *Variable resposta*.

Pel que fa als *missing values*, no n'hi ha cap en aquesta base de dades, tal i com s'indica a la seva descripció oficial.

Abans de res, s'observen les característiques de cada una de les variables i els resultats són els següents.

```{r echo = FALSE, warnings = FALSE}
Xid <- read.csv2("./data/winequality-red.csv")
X <- data.frame(Xid[,-1])
summary(X[,-12])
```

En general, tots els valors semblen normals. L'únic que crida l'atenció és que les variables $\texttt{residual.sugar}$, $\texttt{chlorides}$, $\texttt{sulphates}$ i $\texttt{total.sulfur.dioxide}$ prenen valors molt concentrats a l'extrem esquerre, ja que el tercer quartil i la mediana estan molt allunyats del màxim. Això pot voler dir que hi ha algun outlier que convé eliminar perquè no afecti al nostre anàlisi. Per detectar-ho, es realitza un $\texttt{boxplot}$ d'aquestes variables.

```{r echo = FALSE, fig.align = "center", out.height='70%', out.width='70%'}
par(mfrow=c(2,4))

boxplot(X[,5], main = "chlorides")
a <- which(X$chlorides > 0.15 | X$chlorides < 0.02)

boxplot(X[,4], main = "residual.sugar")
b <- which(X$residual.sugar > 5 | X$residual.sugar < 1)

boxplot(X[,7], main = "total.sulfur.dioxide")
c <- which(X$total.sulfur.dioxide > 150)

boxplot(X[,10], main = "sulphates")
d <- which(X$sulphates > 1.2)

outliers <- union(union(union(a,b),c),d)

cat("Total outliers = ")
length(outliers)

cat("% Outliers = ")
length(outliers)/1599 * 100
```

S'observa que, com era d'esperar, hi ha nombrosos *outliers* en aquestes variables. Donat que el total d'outliers suposa el 10% de les dades, es procedeix a eliminar-los per evitar possibles influències negatives en l'anàlisi. S'observa ara que els valors de les variables estan més repartits.

```{r echo = FALSE, fig.align = "center", out.height='70%', out.width='70%'}
X <- X[-outliers,]

par(mfrow=c(2,4))

boxplot(X[,5], main = "chlorides")
boxplot(X[,4], main = "residual.sugar")
boxplot(X[,7], main = "total.sulfur.dioxide")
boxplot(X[,10], main = "sulphates")
```

# Anàlisi de Components Principals (PCA)

## Breu síntesi

El primer anàlisi que de les dades que es farà és l'**Anàlisi de Components  (PCA)**. Els objectius fonamentals d'aquest estudi són reduir el nombre de variables i realitzar una representació en dues dimensions de les dades (__*biplot*__). El que es busca són combinacions lineals de les variables de la forma $F_i = a_{i1}X_1 + \cdots + a_{1N}X_pN$ tal que $F_1, \cdots, F_N$ (components principals) no estiguin correlats. Aquestes combinacions lineals ens les dóna la descomposició espectral de la matriu de les dades $F = X A$, on A és la matriu de vectors principals. Una vegada calculats aquests components, ens quedarem amb els suficients per explicar un 80% de la variància de les dades o, en el nostre cas, amb els que tinguin un **valor propi major que 1**.

Una vegada feta aquesta descomposició, es pot fer el __*biplot*__ de les dades a partir de $X = FA$. En aquesta representació, val a dir que les distàncies euclidianes entre els punts aproximen les distàncies Mahalanobis entre les observacions reals. A més, la llargada de les fletxes que representen cada variable és una estimació de la seva desviació estàndard. Ara bé, un dels aspectes més interesants és que l'**angle** entre les diferents fletxes representa una estimació de la correlació entre les dues variables, és a dir:

- Si dues fletxes són gairebé paral·leles i amb el mateix sentit, les variables estaran correlades positivament.
- Si dues fletxes són gairebé paral·leles i amb sentits oposats, les variables estaran correlades negativament.
- Si dues fletxes són gairebé ortogonals, les variables no estaran correlades.

Un altre aspecte a tenir en compte, és si s'utilitza la matriu de covariàncies o la de correlacions pels càlculs. Donat que aquestes dades tenen variables amb unitats de mesura diferents, s'utilitzarà la **matriu de correlacions** (motiu pel qual ens quedarem amb els components principals amb valors propis majors que 1), que és invariant respencte les unitats de mesura.

En resum, els objectius d'aquest anàlisi seràn la representació __*biplot*__ de les dades, la **correlació** entre les variables de la base de dades i els diferents **coeficients** dels components principals més representatius, ja que serà un indicador de les variables més importants.

## PCA de les nostres dades.

Abans de res, es construeix un nou *dataset* eliminant la variable resposta, és a dir, la variable $\texttt{quality}$. Tot seguit, es calcula la matriu de correlacions de les dades, així com el seu *scatter plot* per observar aquestes correlacions.

```{r echo = FALSE, fig.align = "center", out.height='50%', out.width='50%'}
db <- X[,-12]
cor(db)
length(which(abs(cor(db)) > 0.3)) - 11
```
```{r echo = FALSE, fig.align = "center"}
library(car)
library(FactoMineR)
library(ade4)
scatterplotMatrix(db)
```

S'observa, tant en la matriu de correlacions com en el plot de les variables que, en general, **no hi ha correlació entre elles**. De fet, la majoria de valors de la matriu de correlació són inferiors a 0.3. Només hi ha 4 casos que cal destacar:

- $\texttt{fixed.acidity}$ i $\texttt{density}$ estan positivament correlades: 0.697.
- $\texttt{fixed.acidity}$ i $\texttt{pH}$ estan negativament correlades: 0.714.
- $\texttt{fixed.acidity}$ i $\texttt{citric.acid}$ estan positivament correlades: 0.697.
- $\texttt{free.sulfur.dioxide}$ i $\texttt{free.sulfur.dioxide}$ estan positivament correlades: 0.646.

Ara bé, en cap d'aquests casos la correlació entre les variables en qüestió és major que 0.75. És a dir, que no són correlacions molt clares. Calculem ara els components principals que s'han explicat a l'apartat anterior.

```{r echo = FALSE, fig.align = "center", out.height='50%', out.width='50%'}
pca.out <- princomp(db, cor = T)
summary(pca.out)
```

S'observa que, per a explicar almenys un 80% de la variabilitat de les dades, es necessiten almenys **5 components principals**, tot i que el cinquè ja té un valor propi menor que 1. Això és degut a què, com s'ha vist a la matriu de correlacions, les variables són força independents, amb pocs casos de correlacions importants, cosa que implica que no podem reduir molt el nombre de variables. Una altra aspecte a destacar és que **no hi ha cap valor propi nul**, fet que ens indica que no hi ha cap variable que sigui combinació lineal directe de les altres.

A continuació es presenta la representació *biplot* corresponent a aquests components principals.

```{r echo = FALSE, fig.align = "center", out.height='50%', out.width='50%'}
biplot(pca.out, xlabs = rep(".", nrow(db), col = "black"))
screeplot(pca.out)
```

El primer que cal dir d'aquesta representació és que només explica el 47.47% de la variabilitat de les dades, ja que s'hi veuen representats només els dos primers components principals. Així doncs, aquesta representació no és del tot fiable. Alguns fets que ho demostres són que, per exemple, les fletxes de les varaibles $\texttt{residual.sugar}$ i $\texttt{density}$ són pràcticament paral.leles i, en canvi, la correlació entre aquestes dues varaibles és de 0.377. Això podria ser degut a què els 2 primers components principals no representen gaire la variabilitat d'aquestes variables i es centren més en altres.

Tot i així, es veur representada molt representada la correlació negativa de la variable $\texttt{fixed.acidity}$ i $\texttt{pH}$, fet que pot voler dir que tenen gran part de la seva variància explicada pels dos primers components. El mateix passsa amb la correlació positiva de $\texttt{fixed.acidity}$ i $\texttt{citric.acid}$.

A continuació, s'analitzen els coeficients dels components principals, per veure quines variables expliquen més.

```{r echo = FALSE, warnings = FALSE}
pca.out$loadings
```

S'observa, com havíem intuït amb el *biplot*, que el primer component representa sobretot la variable $\texttt{fixed.acidity}$. També les variables $\texttt{citric.acid}$, $\texttt{density}$ i $\texttt{pH}$. Això explica que les correlacions que havíem destacat abans es vegin prou representades en el biplot. Una fet que crida l'atenció és que la component que més representa la variable  $\texttt{residual.sugar}$ és la tercera. Això explica que la seva representació en el biplot no fos fiable. Un altre fet destacable és que les variables $\texttt{free.sulfur.dioxide}$ i $\texttt{total.sulfur.dioxide}$ no tenen representació en el primer component.

# Inferència Multivariant

## Breu Síntesi

En segon lloc, s'aplicaran alguns mètodes d'**Inferència Multivariant** en les dades. L'objectiu d'aquest estudi serà descobrir si hi ha diferències estadísticament significatives entre diversos grups de dades, agrupats per la qualitat dels vins. Per detectar aquestes possibles diferències es realitzarà el test de $T^2$ de **Hotelling** (on assumirem igualtat de variàncies entre els grups) i un test de **t-student** (on no assumirem igualtat de variàncies entre els grups). 

En ambdós casos, les hipotesis dels test són les següents: siguin $\mu_1$ i $\mu_2$ els vectors de mitjanes de les variables de dos grups del conjunt de dades,

$$ H_0 : \mu_1 = \mu_2 $$
$$ H_1 : \mu_1 \neq \mu_2 $$

Ara bé, l'estadístic de prova dels tests varia en funció de si s'assumeixen igualtat de variàncies o no en els grups. En cas de que sí, es té que 

$$ T^2 \text{ ha de seguir una } \frac{(n_1 + n_2 -2)p}{n_1 + n_2 -p -1} \digamma_{p,n_1+n_2-p-1} $$

on $T^2 = [\bar{x}_1 - \bar{x}_2 - (\mu_1 - \mu_2)]' ((1/n_1 + 1/n_2)S_p)^{-1}[\bar{x}_1 - \bar{x}_2 - (\mu_1 - \mu_2)]$. En canvi, si no s'assumeix igualtat de variàncies,es té que

$$ T^2 \text{ ha de seguir una } \chi^2$$
on $T^2 = [\bar{x}_1 - \bar{x}_2 - (\mu_1 - \mu_2)]' \left(\frac{1}{n_1} S_1 + \frac{1}{n_2}S_2 \right)^{-1}[\bar{x}_1 - \bar{x}_2 - (\mu_1 - \mu_2)]$.

En ambdós casos, s'assumeix que les variables dels grups segueixen una distribució normal multivariant. Llavors, el primer que s'haurà de fer abans d'aplicar aquests tests a les nostres dades, serà mirar si podem assumir normalitat mulivariant. Pel que fa a la divisió dels grups, es realitzaran dues divisions diferents: una de dos grups (qualitat inferior o igual a 5 i qualitat superior a 5) i una de tres grups (qualitat 3-4, qualitat 5-6, qualitat 7-8).

## Inferència multivariant en les nostres dades.

### Distribució normal multivariant.

Com s'ha dit anteriorment, abans de poder estudiar si hi ha diferències estadísticament significatives entre grups de dades, hem d'estar segurs que podem assumir normalitat en les variables. Per això es comprovarà que la relació entre les distàncies de les variables i els quartils corresponents a una $\chi^2_p$ amb $p$ graus de llibertat (número de variables, 11 en aquest cas) sigui lineal.

```{r echo = FALSE, warnings = FALSE}
dbs <- scale(db, scale = F)
dbcovs <- cov(db)

md <- diag(dbs %*% solve(dbcovs, diag(11)) %*% t(dbs))
md <- sort(md)

n <- nrow(db)
rang <- (c(1:n)-0.5)/n
q <- qchisq(rang, 11)
plot(q, md)
abline(0,1, col = "red")
```

S'observa que la relació no és perfectament lineal però ho és suficient per assumir normalitat multivariant en les dades i, per tant, poder aplicar els tests de Hotelling i de *t*-student.

Abans de res, s'han dividit les dades en dos grups (qualitat major o menor que 5) i en tres grups (rangs de qualitat de 3-4, 5-6 i 7-8).

```{r echo = FALSE, warnings = FALSE}
db.menor5 <- db[which(X$quality <= 5),]
db.major5 <- db[-which(X$quality <= 5),]

db.quality34 <- db[which(X$quality < 5),]
db.quality56 <- db[which(X$quality > 4 & X$quality < 7),]
db.quality78 <- db[which(X$quality > 6),]
```

### Test Hotellin i *t*-student

En primer lloc, es realitza en test de Hotelling assumint igualtat de variàncies entre els dos grups de dades: un en què els vins tenen qualitat inferior o igual a 5 i un altre on tenen qualitat major que 5.

```{r echo = FALSE, warnings = FALSE}
library(ICSNP)
HotellingsT2(db.menor5, db.major5)
```

Donat que s'obté un *p-value* < 0.05, s'ha de rebutjar la hipòtesi nula i, per tant, hi ha diferències estadísticament significatives entre les mitjanes dels vins de qualitat 5 o inferior amb els dels vins de qualitat 6 o major. Aquest resultat era d'esperar, ja que en cas contrari, voldria dir que la valoració dels jutges és 100% subjectiva, cosa que sabem que no és del tot certa. Observant les mitjanes, es comprova el resultat. S'observa que sobretot es difereix en les variables $\texttt{volatile.acidity}$, $\texttt{alcohol}$ i $\texttt{total.sulfur.dioxide}$.

```{r echo = FALSE, warnings = FALSE}
colMeans(db.menor5)
colMeans(db.major5)
```

Es calcula a continuació la $T^2$ sense assumir igualtat de variàncies. S'observa que el valor obtingut és força diferent a l'anterior i, per tant, es realitza un test $t$-student sense considerar les variàncies iguals.

```{r echo = FALSE, warnings = FALSE}
(T2 <- (colMeans(db.menor5) - colMeans(db.major5))%*%solve(cov(db.menor5)/nrow(db.menor5) + cov(db.major5)/nrow(db.major5), diag(11))%*%(colMeans(db.menor5) - colMeans(db.major5)))
```

```{r echo=FALSE}
for (i in 1:11){
  print(colnames(db)[i])
  test <- t.test(db.menor5[,i], db.major5[,i], var.equal = F)
  print(test$p.value)
}
```

Analitzant els *p-values*, s'observa que només hi ha diferències significatives entre les variables $\texttt{fixed.acidity}$, $\texttt{volatile.acidity}$, $\texttt{citric.acid}$, $\texttt{chlorides}$, $\texttt{total.sulfur.dioxide}$, $\texttt{density}$, $\texttt{sulphates}$ i $\texttt{alcohol}$. En la resta de variables, no hi ha diferències significatives. Així doncs, aquestes són les variables que principalment permetran dir si un vi és bo o és dolent.

A continuació es realitzarà el mateix anàlisi però comparant els 3 grups especificats anteriorment 2 a 2. Donat que s'ha vist que no es pot assumir igualtat de variables, es realitzarà directament el test *t-student*. En primer lloc, comparem els vins dolents (qualitat 3-4) amb els vins bons (qualitat 7-8).

```{r echo=FALSE}
for (i in 1:11){
  print(colnames(db)[i])
  test <- t.test(db.quality34[,i], db.quality78[,i], var.equal = F)
  print(test$p.value)
}
```

Així doncs, entre aquests dos grups, s'observen diferències estadísticament significatives en les variables $\texttt{fixed.acidity}$, $\texttt{volatile.acidity}$, $\texttt{citric.acid}$, $\texttt{chlorides}$, $\texttt{density}$, $\texttt{sulphates}$, $\texttt{alcohol}$ i $\texttt{pH}$. Es veu que ara hi ha diferències en el pH i no n'hi ha en els nivells totals de Diòxid de Sofre, a diferència d'abans. Tot i així, sembla bastant objectiu que un vi sigui de baixa qualitat a que sigui d'alta qualitat

Es comparen ara els vins dolents (3-4) amb els vins mitjans (5-6).

```{r echo=FALSE}
for (i in 1:11){
  print(colnames(db)[i])
  test <- t.test(db.quality34[,i], db.quality56[,i], var.equal = F)
  print(test$p.value)
}
```

En aquest cas, s'observen diferències en només 6 variables (abans n'hi havia en 8): $\texttt{volatile.acidity}$, $\texttt{citric.acid}$, $\texttt{free.sulfur.dioxide}$, $\texttt{total.sulfur.dioxide}$, $\texttt{pH}$ i $\texttt{sulphates}$. Així doncs, sembla que les diferències entre vins de mitjana qualitat i de baixa qualitat no estan tant clares (tot i que hi segueixen estant).

Per últim, es comparen els vins mitjans (5-6) amb els vins bons (7-8).

```{r echo=FALSE}
for (i in 1:11){
  print(colnames(db)[i])
  test <- t.test(db.quality78[,i], db.quality56[,i], var.equal = F)
  print(test$p.value)
}
```

En aquest cas, veiem diferències estadísticament significatives en totes les variables tret del $\texttt{residual.sugar}$. És a dir, són els grups més diferents i, per tant, quan un vi es bo, es nota.

# Anàlisi Discriminant (LDA/QDA/LogReg)

## Breu síntesi

En tercer lloc, es farà un **Anàlisi Discriminant (LDA/QDA)**, així com també una **Regressió Logística**. Els objectius principals d'aquests estudi són la separació en grups (concretament en dos) de les dades, per així poder reduri la dimensió d'anàlisi (de variables a discriminadors) i, donada una nova observació, poder-la classificar. 

Aixi doncs, l'anàlisi discriminant, consisteix en trobar una **funció discriminant** tal que permeti decidir a quina classe ($\pi_1$ o $\pi_2$) pertany una observació $x$. En el cas del **LDA**, Anàlisi Discriminant *Lineal*, es buscarà aquesta funció tal que sigui lineal. D'inici, es suposa que la distribució de les dades és una Normal Multivariant que, a més, en el cas de LDA es suposa igualtat de variàncies entre els grups ($\Sigma_1 = \Sigma_2 = \Sigma$). Per tant, s'assumeix:

$$ f_k(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)'\Sigma^{-1}(x-\mu_k)\right) \quad k=1,2 $$
L'objectiu de la funció discriminant ha de ser minimitzar el __*ECM*__ (Expected Cost of Misclassification), definit com:

$$ECM = c(1|2)P(1|2)p_2 + c(2|1)P(2|1)p_1$$
on $c(i|j)$ són el número de observacions que pertanyen al grup $j$ però s'han classificat com a grup $i$, $P(i|j)$ ídem però amb probabilitat, i les $p_k$ són les probabilitats *a-priori* de pertànyer a cada un dels grups. Així doncs, minimitzant queda que la funció discriminant de LDA és assignar l'observació $x$ al grup 1 si:

$$ (\bar{x}_1 - \bar{x}_2)'S_p^{-1}x - \frac{1}{2}(\bar{x}_1 - \bar{x}_2)'S_p^{-1}(\bar{x}_1 - \bar{x}_2) \geq \ln\left(\left(\frac{c(1|2)}{c(2|1)}\right)\left( \frac{p_2}{p_1}\right)\right) $$

$$ S_p = \frac{n_1 - 1}{n_1 + n_2 - 2}S_1 + \frac{n_2 -1 }{n_1 + n_2 - 2}S_2 $$ 

En el cas de **QDA**, Anàlisi Discriminant *Quadràtic*, la funció discriminant resultant que s'obté no és lineal sinó quadràtica, degut a què no es suposa la hipòtesi d'igualtat de variàncies ($\Sigma_1 \neq \Sigma_2$) i, per tant, s'assigna l'observació $x$ al grup 1 si:

$$ -\frac{1}{2}x'(S_{1}^{-1} - S_2^{-1})x + (\bar{x}_1'S_{1}^{-1} - \bar{x}_2'S_{2}^{-1})x - k \geq \ln\left(\left(\frac{c(1|2)}{c(2|1)}\right)\left( \frac{p_2}{p_1}\right)\right) $$
$$ k = \frac{1}{2}\ln \left(\frac{|S_1|}{|S_2|} \right) + \frac{1}{2}(\bar{x}_1'S_1^{-1}\bar{x}_1 - \bar{x}_2'S_2^{-1}\bar{x}_2) $$

Una vegada realitzades aquestes classificacions, pot ser interessant tenir una mesura del seu error. Per aquesta finalitat, es tenen diferents opcions:

- *Actual Error Rate* (*AER*), que depèn de les funcions de densitat $f_k(x)$ ($\hat{R}_k$ és la regió dels valors del grup k):

$$ AER = p_1 \int_{\hat{R}_2} f_1(x) dx +  p_2 \int_{\hat{R}_2} f_2(x) dx$$
- *Apparent Eroor Rate* (*APER*), que no depèn de les funcions de densitat $f_k(x)$:

$$ APER = \frac{n_{12} + n_{21}}{n_{1} + n_{2}} $$

on $n_{ij}$ representa els valors de la classe $i$ classificats com a valors de la classe $j$.

## Anàlisi discriminant de les nostres dades

```{r echo = FALSE, warnings = FALSE}
quality <- X$quality
```

```{r echo = FALSE, warnings = FALSE}
Xs <- scale(db, center = T, scale = T)
```

Abans de realitzar qualsevol tipus d'anàlisi, s'estandaritzen les dades per apropar-les a una distribució normal (assumpció necessària per aquest estudi, com s'ha comentat anteriorment). En segon lloc, donat que la gran majoria de vins estan valorats al 5 o al 6 (tal i com es pot observar en l'histograma), es decideix que els dos grups sobre els quals s'intentaran agrupar les dades seràn el grup dels vins "dolents" (qualitat inferior o igual a 5) i el grup dels vins "bons".

```{r}
hist(quality)
bin <- ifelse(quality > 5, "Bo", "Dolent")
```

### Anàlisi de Discriminant Lineal (LDA)

Ara les dades ja estan preparades per realitzar l'anàlisi discriminant. En primer lloc es suposaran que els grups tenen variàncies iguals i es realitzarà l'anàlisi discriminant lineal. El primer que es fa és calcular-ne el coeficients per veure a quines variables es dóna més importància a l'hora de classificar:

```{r echo = FALSE, warnings = FALSE}
# 4. Fem un LDA i donem els coeficients
library(MASS)
lda.out <- lda(bin ~ Xs)
lda.out$scaling
```

S'observa que les variables que tenen més importantància en la discriminació són: 

- $\texttt{alcohol}$, que té un coeficient negatiu.
- $\texttt{total.sulfur.dioxide}$, que té un coeficient positiu.
- $\texttt{volatile.acidity}$, que té un coeficient positiu.
- $\texttt{sulphates}$, que té un coeficient negatiu

Tots són ingredients explícitament químics que clarament es pot veure com poden discriminar entre vins per la seva particularitat.

En canvi, les menys importants són, $\texttt{residual.sugar}$, $\texttt{density}$ i el $\texttt{pH}$, que com es pot veure són mesures molt més genèriques, que depenen de molts components químics i per tant són bastant més insignificants a l'hora de discriminar.

Una primera mesura de la precisió de la separació en els dos grups pot ser la matriu de confusió del LDA. Els seus valors són els següents:

```{r echo = FALSE, warnings = FALSE}
# 5. Taula de confusió
lda.pred <- predict(lda.out)
(lda.ct <- table(bin, lda.pred$class))
err.lda <- 1- sum(diag(lda.ct))/sum(lda.ct)
cat("\n")
cat("APER de LDA:", err.lda)

```

L'error de classificació obtingut és del 25% en la discriminació que en principi són bones notícies ja que queda demostrat que hi ha quelcom que separa els vins bons i els vins dolents. Es pot veure de quin caire són els vins que han estat classificats erròniament:

```{r echo = FALSE, warnings = FALSE}
par(mfrow=c(1,2))
missclass.lda <- which(bin != lda.pred$class)
cat("Qualitat de tots els vins\n")
cat("\n")
summary(as.factor(quality))
cat("Qualitat dels vins erròniament classificats amb LDA\n")
cat("\n")
summary(as.factor(quality[missclass.lda]))

hist(quality)
hist(quality[missclass.lda], xlim = c(3,8))
```

En les dades es pot veure que els vins de $\geq 7$ i els de $\leq 4$ són classificats correctament en gran majoria. Els més difícilment de classificar són, com era d'esperar, els vins de qualitat 5 i 6. Proporcionalment, veiem una lleugera tendència a classificar erròniament vins de qualitat 4 i 6 (a preu, suposem de discriminar bé quasi perfecte els de qualitat 3, 7 i 8).

### Anàlisi de Discriminant Quadràtic (QDA)

A continuació, es realitza un anàlisi de discriminant quadràtic (es suposarà que els dos grups tenen matrius de covariància diferents) per poder comparar-lo amb el lineal.

```{r echo = FALSE, warnings = FALSE}
# 6. QDA
qda.out <- qda(bin ~ Xs)
```

```{r echo = FALSE, warnings = FALSE}
qda.pred <- predict(qda.out)
(qda.ct <- table(bin, qda.pred$class))
err.qda <- 1 -sum(diag(qda.ct))/sum(qda.ct)
cat("\n")
cat("APER de QDA:", err.qda)
```

Tal i com s'ha fet anteriorment, es calcula la matriu de confusió del model quadràtic i s'observa que el resultat és gairebé igual que amb LDA. Ídem que abans, s'aprofundeix més en els vins mal classificats i els resultats són els següents:

```{r echo = FALSE, warning= FALSE}
par(mfrow=c(1,2))
missclass.qda <- which(bin != qda.pred$class)
print("Qualitat de tots els vins")
summary(as.factor(quality))
print("Qualitat dels vins erròniament classificats amb QDA")
summary(as.factor(quality[missclass.qda]))

hist(quality)
hist(quality[missclass.qda], xlim = c(3,8))
```

En efecte, els vins erròniament classificats fora del 5 i 6 ronden els mateixos nombres que en l'anàlisi lineal. És a dir, s'obtenen uns resultats molt similars al LDA.

```{r echo = FALSE, warning= FALSE}
quals <- sort(unique(quality))

cat("Wines missclassified with LDA and QDA simultanoeusly\n")
for (k in quals) {
  I.k <- intersect(which(quality[missclass.lda] == k),
                   which(quality[missclass.qda] == k))
  
  print(paste("Quality =", k))
  print(length(I.k))
}
```

Ara bé, encara que el nombre de classificats erròniament és el mateix, sorprèn que el LDA i el QDA han coincidit molt poc entre els vins erròniament classificats. És a dir, que els vins que LDA ha classificat bé, QDA ha classificat malament i viceversa (en la majoria de casos).

### Regressió logística (LogReg)

Com a tercera opció per classificar els dos grups de vins, es provarà de fer una **Regressió Logística** (*Logistic Regression*), un model lineal generalitzat que té com a *link function* la funció logaritme i com a distribució de les dades d'entrada, la família binomial.

```{r echo = FALSE, warning= FALSE}
# 7. Logistic regression
qual.bin <- quality > 5
mod <- glm(qual.bin ~ Xs,
           family = "binomial")

log.pred <- predict(mod, type = "response")
(log.ct <- table(qual.bin, log.pred > 0.5))
err.log <- 1- sum(diag(log.ct))/sum(log.ct)

cat("\n")
cat("APER de LogReg:", err.log)
```
S'observa que s'obté un percentatge d'error lleugerament superior als altres mètodes però semblant. A continuació, s'analitzen amb més profunditat els valors mal classificats.

```{r echo = FALSE, warning= FALSE}
par(mfrow=c(1,2))
missclass.log <- which(qual.bin != (log.pred > 0.5))
cat("Qualitat de tots els vins\n")
summary(as.factor(quality))
cat("Qualitat dels vins erròniament classificats amb LogReg\n")
summary(as.factor(quality[missclass.log]))

hist(quality)
hist(quality[missclass.log], xlim = c(3,8))
```

S'obtenen resultats també similars als dels altres dos mètodes. A continuació es calculen els vins que es classifiquen erròniament en els tres mètodes:

```{r echo = FALSE, warning= FALSE}
quals <- sort(unique(quality))

cat("Wines missclassified with LDA, QDA simultanoeusly with LogReg\n")
cat("Missclassified with LDA and LogReg / Missclassified with QDA and LogReg / Union of missclassified with LDA and LogReg and with QDA and LogReg\n")

for (k in quals) {
  Q.k <- intersect(which(quality[missclass.qda] == k),
                   which(quality[missclass.log] == k))
  L.k <- intersect(which(quality[missclass.lda] == k),
                   which(quality[missclass.log] == k))
  
  U.k <- union(Q.k, L.k)
  print(paste("Quality =", k))
  print(paste(paste(length(L.k), length(Q.k)), length(U.k)))
}
```

S'observa que la regressió logística classifica erròniament alguns altres vins que els altres mètodes classificaven bé, sobretot en els vins de qualitat de 5 i 6. Es recullen els resultats dels tres mètodes en una taula de comparació:

```{r echo = FALSE, warning= FALSE}
# 8. Taula de comparació
comp.table <- data.frame(ERR.lda = err.lda,
                         ERR.qda = err.qda,
                         ERR.log = err.log)
print(comp.table)

print("Qualitat de tots els vins")
summary(as.factor(quality))
print("Qualitat dels vins erròniament classificats amb LDA")
summary(as.factor(quality[missclass.lda]))
print("Qualitat dels vins erròniament classificats amb QDA")
summary(as.factor(quality[missclass.qda]))
print("Qualitat dels vins erròniament classificats amb LogReg")
summary(as.factor(quality[missclass.log]))
```

# Anàlisi clúster

## Breu síntesi

Un altre dels anàlisis que realitzarem sobre les dades és l'**Anàlisi Clúster**, l'anàlisi d'agrupaments. Tal i com indica el seu nom, amb aquest estudi es buscaran els grups naturals que hi ha dins de les dades. Aquests grups estan formats per observacions "semblants" entre elles, on aquest nivell de semblança s'ha de definir prèviament i s'ha d'entendre com la distància entre les observacions. A més, aquest estudi ens permet reduir el conjunt de dades de $n$ observacions a $k$ grups prou semblans.

Pel que fa als algoritmes que s'utilitzen per trobar aquests grups, bàsicament els dividirem en 3 tipus: **jeràrquics**, **no jeràrquics** i els mètodes __*model-based*__. En relació als primers, val a dir que, un cop una observació s'ha assignat a un grup, ja no canvia de grup. L'algoritme més utilitzat és l'**aglomeració jeràrquica**, que simplement va ajuntant a cada pas les observacions/grups que estiguin a menor distància. Pel càlcul de la distància entre dos grups ja creats, es pot considerar:

- **Single linkage**: La distància entre les observacions més properes entre els dos grups. Sensible als outliers.
- **Complete linkage**: La distància entre les observacions més llunyanes entre els dos grups. Sensible als outliers.
- **Average linkage**: La mitjana de la distància entre les observacions dels dos grups. Menys sensible als outliers.
- **Centroid distance**: Es defineix la distància entre grups com $d_{rs}^2 = \sum_{j=1}^p (\bar{x}_{rj} - \bar{x}_{sj})^2$, on $r$ i $s$ són els dos grups. Menys sensible als outliers.
- **Ward's criterion**: Es defineix $\Delta = \frac{n_r n_s}{n_r + n_s}d_{rs}^2$ i s'agrupen els dos grups amb $\Delta$ mínim. Menys sensible als outliers.

Per altra banda, en els algoritmes **no jeràrquics**, una observació pot anar canviant de grup a mesura que avança el procediment. L'algoritme més utilitzat en aquest cas és el __*K-Means*__. La idea és anar calculant pas a pas els centres de cada grup i anar ajustant-los a les dades. Es comença amb un conjunt de centres aleatòri i s'assignen les observacions més properes a cada centre. A cada pas es recalculen els centres i es reassignen les dades. Quan en un pas ja no hi ha més reassignacions, s'acaba. En nombre de grups $K$ és fixat.

Per últim, així com tant els algoritmes jeràrquics o no jeràrquics no feien cap tipus d'assumpció sobre la distribució de les dades, en els mètodes **model-based** s'utilitzen models probabilísics concrets per agrupar les dades. La idea és que s'entenen les dades com un *finite mixture model* 

$$ g(x|\pi, \theta) = \pi_1f_1(x|\theta_1) + \cdots + \pi_kf_k(x|\theta_k)$$

on les $f_i$ són les distribucions de probabilitat de cada un dels $k$ grups, que normalment es té $f_i$ ~ $N(\mu, \Sigma)$. A partir d'aquesta assumpció, es calculen les probabilitats de que cada observació $x_i$ pertanyi al grup $i$ com

$$ \frac{\pi_i f_i(x_j|\theta_i)}{\sum_{i=1}^k \pi_i f_i(x_j|\theta_i)} $$

El procediment en aquests algoritmes probabilístics és estimar el *finite mixture model* amb màxima versemblança, calcular les probabilitats *a-posteriori* de cada observació a cada grup i assignar-la al grup on tingui una probabilitat més elevada.

## Anàlisi Clúster de les nostres dades

Tal i com ja s'havia fet abans, s'utilitzarà un *dataset* on s'ha extret la variable resposta $\texttt{quality}$. El primer que es fa és l'estandarització de les dades per aconseguir que totes tinguin mitjana zero, anomenada $X_s$. A continuació, es calcula la matriu de distàncies $D$ euclidianes entre les observacions de les dades i s'observa que la distància més gran és 12.98895.

```{r echo=FALSE}
Xs <- scale(db)
D <- dist(Xs, method = "euclidean")
```

A continuació, es procedeix a realitzar-se l'anàlisi clúster de les dades amb cada un dels mètodes explicats a l'apartat anterior.

### Anàlisi Cluster Jeràrquic

En primer lloc, es realitza l'aglomeració jeràrquica de les dades amb 4 tipus diferents de distàncies entre grups (indicades com a títol de cada *plot*). Donat que la variable resposta d'aquest anàlisi és la qualitat del vi, s'haurien de veure agrupacions d'observacions amb qualitats similars, ja que s'entén que si dues observacions tenen la mateixa qualitat, són observacions properes. Així doncs, donat que la qualitat s'ha valorat de l'1 al 10, s'haurien de detectar un nombre menor que 10 de grups clars

```{r echo = FALSE, warning= FALSE}
library(colorspace)
library(viridis)
library(dendextend)
n_quality <- length(unique(X$quality))
#cols <- c("red","green","yellow","blue", "black", "orange")
cols <- magma(n_quality)
col_quality <- cols[X$quality]
```

```{r echo = FALSE, warnings = FALSE}

par(mfrow=c(2,2))

closest.neigh <- as.dendrogram(hclust(D, method = "single"))
col_quality <- col_quality[order.dendrogram(closest.neigh)]
closest.neigh <- set(closest.neigh, "labels_colors", col_quality)
plot(closest.neigh, main="Single linkage", cex = 0.3)

farthest.neigh <- as.dendrogram(hclust(D, method = "complete"))
col_quality <- col_quality[order.dendrogram(farthest.neigh)]
farthest.neigh <- set(farthest.neigh, "labels_colors", col_quality)
plot(farthest.neigh, main="Complete linkage", cex = 0.3)

average.neigh <- as.dendrogram(hclust(D, method = "average"))
col_quality <- col_quality[order.dendrogram(average.neigh)]
average.neigh <- set(average.neigh, "labels_colors", col_quality)
plot(average.neigh, main="Average linkage", cex = 0.3)

ward.neigh <- as.dendrogram(hclust(D, method = "ward.D2"))
col_quality <- col_quality[order.dendrogram(ward.neigh)]
ward.neigh <- set(ward.neigh, "labels_colors", col_quality)
plot(ward.neigh, main="Ward's criterion", cex = 0.3)
```

En el cas del *Single linkage*,  sembla ser que hi ha un grup molt gran i petits grupets. Això podria significar que la variabilitat de la qualitat de les observacions és petita, és a dir, que tenim moltes puntuacions iguals. Si es volguéssin agrupar les dades en un nombre més reduït de grups seguint aquesta agrlomeració, quedaria un grup amb un porcentatge molt elevat de les observacions i grups amb un percentatge molt petit. Així doncs, en aquest cas, no podem dir que resultin detectables les diferents qualitats de vi en aquesta agrupació. Per poder diferenciar un nombre raonable de grups, s'hauria de tallar a una distància de més de 3.

En el cas del *Complete linkage*, sembla ser que hi ha unes agrupacions de tamanys més iguals. De fet, es poden veure clarament tres grups, que es podria suposar que són agrupacions de vi de alta qualitat, vi de baixa qualitat i vi de qualitat mitjana. En aquest cas doncs, a diferència de l'altre, sembla que sí que són detectables les diferents qualitats del vi. Per poder diferenciar aquests 3 grups clars, hauríem de tallar a una distància de més de 10.

En el cas del *Average linkage*, es té un comportament semblant al de *Single linkage*: s'acaba formant un grup molt gran i grups més reduïts. Així que tampoc serveix per detectar les diferents qualitats del vi. Per poder diferenciar un nombre raonable de grups, s'hauria de tallar a una distància de més de 6.

Per últim, en el cas del *Ward's criterion* és el cas on més clar es veu que es formen grups mes o menys del mateix tamany i iguals. En concret, es veu que es formen 4 grups clars i, per tant, són detectables les diferents qualitats del vi. Per poder diferenciar un nombre raonable de grups, s'hauria de tallar a una distància de més de 40.

Ara bé, donat que s'han marcat de colors diferents les observacions, tenint en compte la seva puntuació, s'observa que a cada grup hi ha barreja de puntuacions. Això no és preocupant, ja que sabem que la puntuació ha estat posada de manera relativament subjectiva i pot no estar perfectament correlacionada amb el valor de les dades, que és en el que es basa aquest algoritme per fer els grups. Per poder diferenciar aquests 4 grups clars, s'hauria de tallar a una distància de més de 3. En definitiva, s'observa que dues observacions de qualitats prou diferents poden caure dins el mateix clúster. Un altre detall a remarcar, és que hi ha moltes observacions de la mateixa qualitat.

A continuació, s'analitza en més profunditat com han agrupat aquests algoritmes, tallant l'arbre en cada cas per formar un nombre en concret de clústers. En el primer cas, el *Single Linkage*, s'ha tallat l'arbre per obtenir 3 clústers i el resultat és bastant dolent, ja que com s'havia comentat abans, es crea un clúster molt grans i dos de molt petits (de 2 i 1 observació). A més, el clústers petits contenen observacions amb qualitat 5, que és la més abundant al clúster gran.

```{r echo = FALSE, warnings = FALSE}
clusters.closest <- cutree(closest.neigh, 3)
table(clusters.closest)
(compar.closest <- table(clusters.closest, X$quality))
```

En el cas del *Complete Linkage*, s'observa que si es creen tres grups, les mides dels grups són bastant similars. Tot i que tots els grups contenen moltes observacions de qualitat 5 i 6, s'observa que les observacions de qualitat més baixa s'han concentrat al clúster 1 i les de qualitat més alta al clúster 2. Així doncs, s'ha realitzat una separació més o menys depenent de la qualitat. A més, en el clúster "d'alta qualitat" és on menys observacions de qualitat 5 hi ha i en el clúster de "baixa qualitat" és on més n'hi ha.

```{r echo = FALSE, warnings = FALSE}
clusters.farthest <- cutree(farthest.neigh, 3)
table(clusters.farthest)
(compar.farthest <- table(clusters.farthest, X$quality))
```

En el cas de l'*Average Linkage*, es té una situació semblant a la del *Single Linkage*: un grup molt gran i dos de petits amb 3 i 1 observacions. Per tant, no es detecten bé les diferents qualitats del vi.

```{r echo = FALSE, warnings = FALSE}
clusters.average <- cutree(average.neigh, 3)
table(clusters.average)
(compar.average <- table(clusters.average, X$quality))
```

Per últim, en el cas del *Ward Criterion*, s'observa que es poden crear 4 grups de tamanys similars. A més, al primer grup es concentren gariebé totes les observacions de pitjor qualitat (3 i 4), en el segon les de qualitat una mica millor (4 i 5), en el tercer és on abunden més les de qualitat mitjana-alta (6 i 7) i en l'últim és on hi ha la gran majora de qualitat alta (7 i 8). Per tant, aquest és el cas on més clarament s'agrupa segons la qualitat del vi.

```{r echo = FALSE, warnings = FALSE}
clusters.ward <- cutree(ward.neigh, 4)
table(clusters.ward)
(compar.ward <- table(clusters.ward, X$quality))
```
Una aproximació de l'error en el cas del *Ward Criterion* és 44,84%.
```{r echo = FALSE, warnings = FALSE}
ward.maxs <- apply(compar.ward, 1, which.max)
ward.misclass <- 0
for (k in 1:4) ward.misclass <- ward.misclass + sum(compar.ward[k,-ward.maxs[k]])
(ward.err <- ward.misclass/sum(compar.ward))
```

En conclusió, si s'estableixen com a criteris de distància entre grups el *Ward Criterion*, un algoritme d'agrupació jeràrquic és capaç d'agrupar les observacions més o menys per qualitat. També s'observa que les qualitats altes o les qualitats baixes són les que millor es detecten, cosa que fa pensar que ha d'haver-hi detalls prou significants en les dades fisicoquímiques per diferenciar un vi dolent d'un vi molt bo.

### Anàlisi Clúster No Jeràrquic

En segon lloc, s'aplicarà un algoritme no jeràrquic per agrupar les observacions. En concret, s'aplicarà l'algoritme **K-Means** amb $K=4$, per poder-ho comparar amb l'aglomeració jeràrquica amb el criteri de Ward utilitzada anteriorment.

```{r echo = FALSE, warnings = FALSE}
set.seed(123)
clusters.kmeans <- kmeans(Xs, 4, nstart = 50)
clusters.kmeans$size
clusters.kmeans$centers
clusters.kmeans$betweenss / clusters.kmeans$totss

(compar.kmeans <- table(X$quality, clusters.kmeans$cluster))
```

S'observa que les dades es divideixen en 4 grups de tamanys similars. Pel que fa a la distribució d'observacions dintre de cada un dels grups tenim:

- Grup 1: Qualitat **baixa** (3-4): La majoria d'observacions de baixa qualitat es concentren el el primer grup. També veiem que s'hi concentren moltes observacions de qualitat 5, cosa que fa pensar que el pas de qualitat 4 a qualitat 5 és mes subjectiu que objectiu. Pel que fa a les variables que més es tenen en compte per calcular el centre d'aquest grup són la $\texttt{volatile.acidity}$, que es té en compte postivament (és a dir, com més, pitjor sembla ser el vi) i el $\texttt{citric.acid}$, que es té en compte positivament (és a dir, com menys, pitjor és el vi). 

- Grup 2: Qualitat **baixa-mitja** (4-5): La majoria d'observacions de qualitat 4 ja hem dit que estan al primer grup, però en el segon grup es concentren la majoria de les observacions restants de qualitats 4 i 5. S'observa que el que més es té en compte en aquest segon grup és les dues variables que es refereixen al Diòxid de Sofre. Les variables que abans marcaven una baixa qualitat del vi, no es tenen tant en compte en aquest grup.

- Grup 3: Qualitat **mitja-alta** (6-7): Una gran part de les observacions de qualitat 6-7 es concentra en aquest grup. Pel que fa a les variables que es destaquen, s'observa que es valora negativament la $\texttt{volatile.acidity}$, fet lògic ja que en els vins de baixa qualitat es valorava positivament, i es valora molt positivament el $\texttt{citric.acid}$, contrari també als vins de baixa qualitat. Un altre variable que sembla ser important en aquest grup és el $\texttt{fixed.acidity}$, que es valora positivament.

- Grup 4: Qualitat **alta** (7-8): Per últim, la majoria d'observacions de qualitat alta es concentren en aquest grup, on es valoren sobretot l'alcohol (variable $\texttt{alcohol}$), positivament, i la densitat (variable $\texttt{density}$) negativament. Ara bé, crida l'atenció que en aquest grup es valori negativament la densitat i en el grup anterior, de qualitat mitjana-alta, aquesta mateixa variable es valori positivament. El mateix passa amb la variable $\texttt{fixed.acidity}$. Ara bé, la variable $\texttt{volatile.acidity}$, igual que abans, es valora negativament. 

Totes aquestes inconsistències en la valoració de cada una de les variables a cada un dels grups es pot assignar a la subjectivitat de la valoració.

S'observa que, en aquest cas, la variabilitat entre els clusters comparada amb la variabilitat total de les dades és molt més reduïda. De fet, una aproximació de l'error és $ BetweenSS / TSS $, és a dir, la suma de quadrats entre els clústers entre la suma de quadrats total. En aquest cas, és 36,9%, inferior a l'aconseguida en el *Ward's Criterion*. Per tant, amb aquestes dades, *K-Means* funciona millor.

```{r echo = FALSE, warnings = FALSE}
kmeans.maxs <- apply(compar.kmeans, 1, which.max)
kmeans.misclass <- 0
for (k in 1:4) kmeans.misclass <- kmeans.misclass + sum(compar.kmeans[k,-kmeans.maxs[k]])
(kmeans.err <- kmeans.misclass/sum(compar.kmeans))
```

### Anàlisi Clúster *Model-Based*

Per últim, anem a agrupar les observacions seguint un model amb 4 mixtures, per poder-ho comparar amb la resta. El primer que s'observa és que els tamanys dels grups són bastant similars. A continuació s'analitzen cada un dels grups:

- Grup 1: Qualitat **baixa-mitja** (4-5): La majoria d'observacions de qualitat 4 o 5 es concentren en aquest primer grup. Una de les variables que es té més en compte és $\texttt{citric.acid}$, negativament. Això ja d'havia observat en l'anàlisi anterior, en el grup dels vins de qualitat baixa. Igual que abans, també es valora positivament el $\texttt{volatile.acidity}$. El $\texttt{fixed acidity}$ es valora negativament (abans s'havia vist que en els vins bons es valorava positivament). 

- Grup 2: Qualitat **alta** (7-8): La majoria de vins d'aquest grup són d'alta qualitat (7-8). Tal i com haviem vist abans, es valoren positivament el $\texttt{fixed.acidity}$ i el $\texttt{citric.acid}$, cosa que encaixa amb el que s'ha vist al grup anterior, de vins de qualitat més baixa. Observem que també, a diferència del grup anterior, el $\texttt{volatile.acidity}$ es valora negativament. En l'anàlisi del *K-Means* s'havia vist que la variable $\texttt{density}$ es valorava positivament en els bons vins i, en aquest cas, veiem que es compleix.

- Grup 3: Qualitat **mitja-alta** (5-6-7): Els vins de qualitat mitja es concentren en aquest grup, on hi ha poc vins de qualitat extremes (baixes o altes). Igual que abans, observem que tenen un pes important positivament les variables relacionades amb el Diòxid de Sofre. Donat que la qualitat és mitjana, les variables que estem detectant que marquen la qualitat del vi, no es tenen tant en compte en aquest grup.

- Grup 4: Qualitat **baixa** (3-4): Els pitjors vins es concentren en aquest grup, tot i que és el grup de tamany menor. Tornem a observar que es valora positivament la variable $\texttt{volatile.acidity}$, igual que en l'altre grup de vins de baixa qualitat. Un detall que cria l'atenció és la valoriació positiva de l'alcohol en aquest grup. Aquest fet s'explica perquè s'observa que també s'han incluït vins de qualitat molt bona en aquest grup, cosa que ha fet que pugi la mitjana.


Tal i com s'ha comentat abans, el fet que apareguin vins de qualiat màxima i mínima en un mateix grup és degut a la subjectivitat de la valoració. S'observa a la gràfica següent que no es veu una clara determinació de les variables per a cada un dels grups.


```{r echo = FALSE, warnings = FALSE}
library(mclust)
cluster.mix <- Mclust(Xs, 4)
```

```{r echo = FALSE, warnings = FALSE}
sum <- summary(cluster.mix, parameters = T)
sum$mean
plot(cluster.mix, what = "classification")
(compar.mix <- table(cluster.mix$classification, X$quality))
mix.maxs <- apply(compar.mix, 1, which.max)

mix.misclass <- 0
for (k in 1:4) mix.misclass <- mix.misclass + sum(compar.mix[k,-mix.maxs[k]])
(mix.err <- mix.misclass/sum(compar.mix))
```


# Conclusions

Tal i com s'havia comentat al principi d'aquest exhaustiu anàlisi, l'objectiu era arribar a detectar les variables fisioquímiques que més podien arribar a influir en la qualitat fina del vi. Després de comparar tots els resultats de les diferents tècniques d'anàlisi multivariant que s'han realitzat sobre les dades, podem concloure que les variables que més influeixen en la qualitat del vi i que, per tant, s'han de mirar de potenciar són:

## Acidesa fixada

Amb els tres primers anàlisis, un s'adona de què $\texttt{fixed.acidity}$ es tracta d'una de les variables importants del vi pels següents motius:

- **PCA**: Variable que té una major representació en el primer component principal de les dades, el que explica més variància. Per tant, és una variable important donat que és de les que més varien en les dades.
- **Inferència Multivariant**: En els diferents grups en què s'han dividit les dades (s'han dividit per qualitats del vi), la seva mitjana en cada un d'ells sempre presenta diferències estadísticament significatives. És a dir, és una variable que pren valors significativament diferents en els vins bons i en els dolents:
- **LDA**: És una de les variables que tenia una major importància a l'hora de classificar les dades.
  
A més, s'ha deduit que la $\texttt{fixed.acidity}$ tenia una efecte positiu en el vi (és a dir, que com més alt és el seu valor, més bo és el vi) pel següent motiu:

- **Clúster**: En tots els diferents agrupaments realitzats, aquesta variable té una mitjana considerablement elevada dintre dels grups d'alta qualitat.

## Àcid Cítric 

Val a dir que aquesta variable ($\texttt{citric.acid}$) és de les que té una correlació més destacada amb $\texttt{fixed.acidity}$. Ídem que abans, s'ha detectat que és una de les variables importants pels següents motius:

- **PCA**: Variable que té una representació també important en el primer component principal de les dades. Per tant, és una variable important donat que és de les que més varien en les dades.
- **Inferència Multivariant**: En els diferents grups en què es van dividir les dades (recordem que es van dividir per qualitats del vi), la seva mitjana en cada un d'ells sempre presenta diferències estadísticament significatives.
  
A més, $\texttt{citric.acid}$ té una efecte positiu en el vi (és a dir, que com més alt és el seu valor, més bo és el vi), pel següent resultat:

-  **Clúster**: En tots els diferents agrupaments realitzats, aquesta variable tenia una mitjana considerablement elevada dintre dels grups d'alta qualitat.

## Acidesa volàtil

També s'ha vist que $\texttt{volatile.acid}$ és una variable important, però, a diferència de les altres dues aquesta té un petit efecte diferent. Tot i així, se'n presenten els motius:

- **Inferència Multivariant**: Igual que les anteriors, presentava sempre diferències estadísticament significatives en mitjana entre els grups de diferents qualitats de vins.
- **LDA**: És una de les variables que més en compte es té per realitzar la classificació.
  
Ara bé, en aquest cas $\texttt{volatile.acid}$ té un efecte negatiu en els vins:

- **Clúster**: En tots els agrupaments realitzats, aquesta variable tenia valors considerablement importants en els grups de vins de baixa qualitat.
   

## Altres consideracions

Per contra, també cal remarcar que la variable que menys importànica té en la qualitat del vi és $\texttt{residual.sugar}$, ja que no presentava diferències estadísticament significatives en mitjana en els diferents grups realitzats i en el PCA no tenia representació en els components fins al tercer.

En conclusió, un dels aspectes que sembla marcar la decisió de l'enòleg a l'hora de valorar un vi és l'acidesa i la presència d'àcids en aquests. Així doncs, es recomana a les indústries productores mirar de potenciar aquestes variables.

# Referències

- Apunts de l'assignatura d'*Anàlisi de Dades* del Grau en Ciència i Enginyeria de Dades.
- P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. *Modeling wine preferences by data mining from physicochemical properties*. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
- Cuadras, C. (2008) *Nuevos métodos de Análisis Multivariante*.